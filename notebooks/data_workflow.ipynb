{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29332db5-c197-4388-980b-a8f5ca713abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe51d66c-1220-4e36-a456-b0fca5392b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set configurations on jupysql to directly output data to Pandas and to simplify the output that is printed to the notebook.\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7aee00-95d2-471e-96a3-5a345f232dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql duckdb:///mydb.duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337b9c7d-d089-41f3-a4d1-d43137298ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "Current working directory: C:\\Users\\victoria\\Desktop\\DE\\zz_de\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52dc43c-4f95-4f68-ba38-56c1b13b9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlt pipeline initilised sucessfully!\n",
      "pipeline_name: insurance_payments_orchestration\n"
     ]
    }
   ],
   "source": [
    "# creating dlt pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='insurance_payments_orchestration',\n",
    "    destination='duckdb',\n",
    "    dataset_name='insurance_payments_data'\n",
    ")\n",
    "\n",
    "print(\"dlt pipeline initilised sucessfully!\")\n",
    "print(f\"pipeline_name: {pipeline.pipeline_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ad11b6-3df6-4c59-8548-e8188ba09543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id first_name   last_name                             email  gender  \\\n",
      "0   1     Cobbie      Legier                 clegier0@1688.com    Male   \n",
      "1   2      Roley      Aslott          raslott1@kickstarter.com    Male   \n",
      "2   3       Yves      Aveson                   yaveson2@un.org    Male   \n",
      "3   4      Ogdan  Littledike  olittledike3@theglobeandmail.com    Male   \n",
      "4   5   Carmelle    Kmietsch            ckmietsch4@dropbox.com  Female   \n",
      "\n",
      "       ip_address   claim_id policy_number payment_type payment_amount  \\\n",
      "0  26.157.123.116  CLM-00019    POL-789012        Claim      $45338.29   \n",
      "1  150.243.59.111  CLM-00014    POL-456789      Premium      $37554.73   \n",
      "2  143.104.38.199  CLM-00014    POL-024689       Refund      $18000.17   \n",
      "3   253.76.121.85  CLM-00005    POL-802467      Premium      $21884.43   \n",
      "4   50.208.96.238  CLM-00015    POL-468023   Adjustment      $15019.83   \n",
      "\n",
      "  payment_currency payment_status payment_method payer_id   payee_id  \\\n",
      "0           Shekel         Failed           Card  PAY-002  PAYEE-007   \n",
      "1    Yuan Renminbi         Failed            ACH  PAY-016  PAYEE-015   \n",
      "2    Yuan Renminbi         Failed  Bank Transfer  PAY-001  PAYEE-013   \n",
      "3            Zloty      Completed           Card  PAY-002  PAYEE-018   \n",
      "4              Yen         Failed  Bank Transfer  PAY-004  PAYEE-009   \n",
      "\n",
      "  transaction_timestamp processing_fee  retry_count payment_gateway  \\\n",
      "0              3/9/2024         $12.16            3          Square   \n",
      "1              8/1/2024         $11.66            2           Adyen   \n",
      "2             1/15/2025         $12.95            3          PayPal   \n",
      "3             7/17/2024          $9.65            1          Square   \n",
      "4              4/5/2024         $15.47            2           Chase   \n",
      "\n",
      "  reconciliation_status  \n",
      "0               Matched  \n",
      "1             Exception  \n",
      "2               Matched  \n",
      "3               Matched  \n",
      "4               Matched  \n",
      "\n",
      " Data Quality Checks\n",
      " Null values: 0\n",
      " Duplicate rows: 0\n",
      " Date range: 1/1/2024 to 9/9/2024\n",
      "Data transformations completed successfully!\n",
      "\n",
      " Data loaded successfully!\n",
      "Load info: Pipeline insurance_payments_orchestration load step completed in 0.76 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset insurance_payments_data\n",
      "The duckdb destination used duckdb:///C:\\Users\\victoria\\Desktop\\DE\\zz_de\\insurance_payments_orchestration.duckdb location to store data\n",
      "Load package 1756601545.8642998 is LOADED and contains no failed jobs\n",
      "\n",
      " Database path: C:\\Users\\victoria\\Desktop\\DE\\zz_de\\insurance_payments_orchestration.duckdb\n",
      "\n",
      " Available tables:\n",
      "              table_schema           table_name\n",
      "0  insurance_payments_data          sample_data\n",
      "1  insurance_payments_data           _dlt_loads\n",
      "2  insurance_payments_data  _dlt_pipeline_state\n",
      "3  insurance_payments_data         _dlt_version\n",
      "\n",
      " Records in table 'insurance_payments_data.sample_data': 1000\n",
      "\n",
      " Sample data:\n",
      "   id first_name last_name                     email gender      ip_address  \\\n",
      "0   1     Cobbie    Legier         clegier0@1688.com   Male  26.157.123.116   \n",
      "1   2      Roley    Aslott  raslott1@kickstarter.com   Male  150.243.59.111   \n",
      "2   3       Yves    Aveson           yaveson2@un.org   Male  143.104.38.199   \n",
      "\n",
      "    claim_id policy_number payment_type  payment_amount  ... processing_fee  \\\n",
      "0  CLM-00019    POL-789012        Claim        45338.29  ...          12.16   \n",
      "1  CLM-00014    POL-456789      Premium        37554.73  ...          11.66   \n",
      "2  CLM-00014    POL-024689       Refund        18000.17  ...          12.95   \n",
      "\n",
      "  retry_count total_cost month day_of_week is_completed        _dlt_load_id  \\\n",
      "0           3   45350.45     3    Saturday        False  1756601545.8642998   \n",
      "1           2   37566.39     8    Thursday        False  1756601545.8642998   \n",
      "2           3   18013.12     1   Wednesday        False  1756601545.8642998   \n",
      "\n",
      "          _dlt_id  payment_gateway  reconciliation_status  \n",
      "0  qIRddVMako/HkQ           Square                Matched  \n",
      "1  xDlg/pkK0zEfpA            Adyen              Exception  \n",
      "2  0FgL1me0BsjHdA           PayPal                Matched  \n",
      "\n",
      "[3 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_core_payments_api_with_transformations():\n",
    "    # Calling the API \n",
    "    url = \"https://my.api.mockaroo.com/core_payments.json?key=e1e5c550\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if request worked\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()   # Parse JSON\n",
    "    \n",
    "        # Convert to DataFrame\n",
    "        df_core_payments = pd.DataFrame(data)\n",
    "        \n",
    "        # getting a brief look at the data\n",
    "        print(df_core_payments.head())\n",
    "\n",
    "        # Convert string money fields to numeric\n",
    "        df_core_payments['payment_amount'] = pd.to_numeric(df_core_payments['payment_amount'].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "        df_core_payments['processing_fee'] = pd.to_numeric(df_core_payments['processing_fee'].str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
    "\n",
    "        # Data quality checks\n",
    "        print(\"\\n Data Quality Checks\")\n",
    "        print(f\" Null values: {df_core_payments.isnull().sum().sum()}\")\n",
    "        print(f\" Duplicate rows: {df_core_payments.duplicated().sum()}\")\n",
    "        print(f\" Date range: {df_core_payments['transaction_timestamp'].min()} to {df_core_payments['transaction_timestamp'].max()}\")\n",
    "    \n",
    "        # Basic transformations for insurance payments\n",
    "        df_core_payments['transaction_timestamp'] = pd.to_datetime(df_core_payments['transaction_timestamp'])\n",
    "        df_core_payments['total_cost'] = df_core_payments['payment_amount'] + df_core_payments['processing_fee']\n",
    "        df_core_payments['month'] = df_core_payments['transaction_timestamp'].dt.month\n",
    "        df_core_payments['day_of_week'] = df_core_payments['transaction_timestamp'].dt.day_name()\n",
    "        df_core_payments['is_completed'] = df_core_payments['payment_status'] == 'Completed'\n",
    "    \n",
    "        # Adding data quality assertions for insurance payments\n",
    "        assert df_core_payments['payment_amount'].min() > 0, \"Payment amount should be positive\"\n",
    "        assert df_core_payments['processing_fee'].min() >= 0, \"Processing fee should be non-negative\"\n",
    "        assert df_core_payments['total_cost'].min() > 0, \"Total cost should be positive\"\n",
    "        assert df_core_payments['retry_count'].min() >= 0, \"Retry count should be non-negative\"\n",
    "    \n",
    "        print(\"Data transformations completed successfully!\")\n",
    "    \n",
    "        # yielding records for dlt\n",
    "        for record in df_core_payments.to_dict(orient=\"records\"):\n",
    "            yield record\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "\n",
    "\n",
    "# Load data into dlt pipeline\n",
    "info = pipeline.run(\n",
    "    load_core_payments_api_with_transformations(),\n",
    "    table_name=\"sample_data\",\n",
    "    write_disposition=\"replace\"\n",
    ")\n",
    "\n",
    "print(f\"\\n Data loaded successfully!\")\n",
    "print(f\"Load info: {info}\")\n",
    "\n",
    "\n",
    "# Get the database path and connect directly to DuckDB\n",
    "db_path = pipeline.sql_client().credentials.database\n",
    "print(f\"\\n Database path: {db_path}\")\n",
    "\n",
    "# Connect to DuckDB and check tables with proper schema handling\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "all_tables = con.execute(\"\"\"\n",
    "    SELECT table_schema, table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_type = 'BASE TABLE'\n",
    "      AND table_schema != 'information_schema'\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "\n",
    "print(f\"\\n Available tables:\")\n",
    "print(all_tables)\n",
    "\n",
    "\n",
    "# Find the data table (exclude dlt internal tables)\n",
    "data_tables = all_tables[~all_tables['table_name'].str.startswith('_dlt')]\n",
    "if not data_tables.empty:\n",
    "    table_schema = data_tables.iloc[0]['table_schema']\n",
    "    table_name = data_tables.iloc[0]['table_name']\n",
    "    full_table_name = f\"{table_schema}.{table_name}\"\n",
    "    \n",
    "    row_count = con.execute(f\"SELECT COUNT(*) FROM {full_table_name}\").fetchone()[0]\n",
    "    print(f\"\\n Records in table '{full_table_name}': {row_count}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    sample = con.execute(f\"SELECT * FROM {full_table_name} LIMIT 3\").fetchdf()\n",
    "    print(f\"\\n Sample data:\")\n",
    "    print(sample)\n",
    "else:\n",
    "    print(\"\\n No data tables found in the database\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76b88c2-501e-46da-b778-d2e543e8d89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to DuckDB at: C:\\Users\\victoria\\Desktop\\DE\\zz_de\\insurance_payments_orchestration.duckdb\n",
      "\n",
      " Available tables:\n",
      "              table_schema           table_name\n",
      "0  insurance_payments_data          sample_data\n",
      "1  insurance_payments_data           _dlt_loads\n",
      "2  insurance_payments_data  _dlt_pipeline_state\n",
      "3  insurance_payments_data         _dlt_version\n",
      "\n",
      " Using table: insurance_payments_data.sample_data\n",
      "\n",
      " Summary Statistics:\n",
      " total_records  unique_policies  total_payment_amount  total_processing_fees  total_cost_with_fees  avg_payment_amount  avg_processing_fee      earliest_transaction        latest_transaction  completed_payments  failed_payments  pending_payments\n",
      "          1000               20            25609900.8               13509.85           25623410.65          25609.9008            13.50985 2024-01-01 01:00:00+01:00 2025-08-28 01:00:00+01:00                 212              189               211\n",
      "\n",
      "Payments by Type:\n",
      "  payment_type  record_count  total_payment_amount  total_processing_fees  \\\n",
      "0   Adjustment           258            6879363.05                3480.31   \n",
      "1      Premium           249            6541738.31                3453.99   \n",
      "2        Claim           251            6260003.43                3264.95   \n",
      "3       Refund           242            5928796.01                3310.60   \n",
      "\n",
      "   total_cost_with_fees  avg_payment_amount  avg_processing_fee  \n",
      "0            6882843.36        26664.197868           13.489574  \n",
      "1            6545192.30        26272.041406           13.871446  \n",
      "2            6263268.38        24940.252709           13.007769  \n",
      "3            5932106.61        24499.157066           13.680165  \n",
      "\n",
      "Payments by Gateway:\n",
      "  payment_gateway  record_count  total_payment_amount  total_processing_fees  \\\n",
      "0           Chase           223            5720225.62                3049.81   \n",
      "1          PayPal           210            5531055.38                2804.95   \n",
      "2          Stripe           192            5048724.20                2540.30   \n",
      "3           Adyen           199            4955692.56                2663.64   \n",
      "4          Square           176            4354203.04                2451.15   \n",
      "\n",
      "   avg_payment_amount  successful_payments  failed_payments  \\\n",
      "0        25651.235964                   53               46   \n",
      "1        26338.358952                   48               39   \n",
      "2        26295.438542                   45               39   \n",
      "3        24902.977688                   32               37   \n",
      "4        24739.790000                   34               28   \n",
      "\n",
      "   failure_rate_percent  \n",
      "0                 20.63  \n",
      "1                 18.57  \n",
      "2                 20.31  \n",
      "3                 18.59  \n",
      "4                 15.91  \n",
      "\n",
      "Payments by Status:\n",
      "  payment_status  record_count  total_payment_amount  avg_payment_amount  \\\n",
      "0      Completed           212            5280262.37        24906.897972   \n",
      "1        Pending           211            5596707.09        26524.678152   \n",
      "2       Disputed           201            5204907.41        25895.061741   \n",
      "3         Failed           189            4748426.07        25123.947460   \n",
      "4     Processing           187            4779597.86        25559.346845   \n",
      "\n",
      "   percentage_of_total  \n",
      "0                 21.2  \n",
      "1                 21.1  \n",
      "2                 20.1  \n",
      "3                 18.9  \n",
      "4                 18.7  \n",
      "\n",
      " DuckDB connection closed\n"
     ]
    }
   ],
   "source": [
    "# Connect to DuckDB and query the loaded data\n",
    "# Get the database path from the pipeline\n",
    "db_path = pipeline.sql_client().credentials.database\n",
    "print(f\" Connected to DuckDB at: {db_path}\")\n",
    "\n",
    "# Connect to DuckDB\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# Get available tables with proper schema handling\n",
    "all_tables = con.execute(\"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_type = 'BASE TABLE' AND table_schema != 'information_schema'\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"\\n Available tables:\")\n",
    "print(all_tables)\n",
    "\n",
    "# Find our data table (exclude dlt internal tables)\n",
    "data_tables = all_tables[~all_tables['table_name'].str.startswith('_dlt')]\n",
    "\n",
    "if data_tables.empty:\n",
    "    print(\"No data tables found. Please run the data loading cell first.\")\n",
    "else:\n",
    "    table_schema = data_tables.iloc[0]['table_schema']\n",
    "    table_name = data_tables.iloc[0]['table_name']\n",
    "    full_table_name = f\"{table_schema}.{table_name}\"\n",
    "    \n",
    "    print(f\"\\n Using table: {full_table_name}\")\n",
    "    \n",
    "    # Query 1: Basic summary statistics\n",
    "    print(\"\\n Summary Statistics:\")\n",
    "    summary_query = f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(DISTINCT policy_number) as unique_policies,\n",
    "        SUM(payment_amount) as total_payment_amount,\n",
    "        SUM(processing_fee) as total_processing_fees,\n",
    "        SUM(total_cost) as total_cost_with_fees,\n",
    "        AVG(payment_amount) as avg_payment_amount,\n",
    "        AVG(processing_fee) as avg_processing_fee,\n",
    "        MIN(transaction_timestamp) as earliest_transaction,\n",
    "        MAX(transaction_timestamp) as latest_transaction,\n",
    "        COUNT(CASE WHEN payment_status = 'Completed' THEN 1 END) as completed_payments,\n",
    "        COUNT(CASE WHEN payment_status = 'Failed' THEN 1 END) as failed_payments,\n",
    "        COUNT(CASE WHEN payment_status = 'Pending' THEN 1 END) as pending_payments\n",
    "    FROM {full_table_name}\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_result = con.execute(summary_query).fetchdf()\n",
    "    print(summary_result.to_string(index=False))\n",
    "\n",
    "    # Query 2: Payments by Type \n",
    "    print(\"\\nPayments by Type:\")\n",
    "    type_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_type,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_payment_amount,\n",
    "        SUM(processing_fee) as total_processing_fees,\n",
    "        SUM(total_cost) as total_cost_with_fees,\n",
    "        AVG(payment_amount) as avg_payment_amount,\n",
    "        AVG(processing_fee) as avg_processing_fee\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_type\n",
    "    ORDER BY total_payment_amount DESC\n",
    "    \"\"\"\n",
    "    type_result = con.execute(type_query).fetchdf()\n",
    "    print(type_result)\n",
    "\n",
    "    # Query 3: Payments by Gateway \n",
    "    print(\"\\nPayments by Gateway:\")\n",
    "    gateway_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_gateway,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_payment_amount,\n",
    "        SUM(processing_fee) as total_processing_fees,\n",
    "        AVG(payment_amount) as avg_payment_amount,\n",
    "        COUNT(CASE WHEN payment_status = 'Completed' THEN 1 END) as successful_payments,\n",
    "        COUNT(CASE WHEN payment_status = 'Failed' THEN 1 END) as failed_payments,\n",
    "        ROUND(COUNT(CASE WHEN payment_status = 'Failed' THEN 1 END) * 100.0 / COUNT(*), 2) as failure_rate_percent\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_gateway\n",
    "    ORDER BY total_payment_amount DESC\n",
    "    \"\"\"\n",
    "    gateway_result = con.execute(gateway_query).fetchdf()\n",
    "    print(gateway_result)\n",
    "\n",
    "    # Query 4: Payments by Status\n",
    "    print(\"\\nPayments by Status:\")\n",
    "    status_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_status,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_payment_amount,\n",
    "        AVG(payment_amount) as avg_payment_amount,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage_of_total\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_status\n",
    "    ORDER BY record_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    status_result = con.execute(status_query).fetchdf()  \n",
    "    print(status_result)\n",
    "\n",
    "con.close()\n",
    "print(\"\\n DuckDB connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f26477-3ae1-4e4b-851d-925987df3a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created:\n",
      "  - summary_statistics.csv\n",
      "  - payment_type_result.csv\n",
      "  - payment_status_result.csv\n",
      "  - gateway_result.csv\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"../output\", exist_ok=True)\n",
    "\n",
    "# Get database path and connect\n",
    "db_path = pipeline.sql_client().credentials.database\n",
    "con = duckdb.connect(db_path)\n",
    "\n",
    "# Get table name with proper schema handling\n",
    "all_tables = con.execute(\"\"\"\n",
    "    SELECT table_schema, table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_type = 'BASE TABLE' AND table_schema != 'information_schema'\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "data_tables = all_tables[~all_tables['table_name'].str.startswith('_dlt')]\n",
    "\n",
    "if not data_tables.empty:\n",
    "    table_schema = data_tables.iloc[0]['table_schema']\n",
    "    table_name = data_tables.iloc[0]['table_name']\n",
    "    full_table_name = f\"{table_schema}.{table_name}\"\n",
    "    \n",
    "    # Export summary results to CSV\n",
    "    summary_query = f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_records,\n",
    "        COUNT(DISTINCT policy_number) as unique_policies,\n",
    "        SUM(payment_amount) as total_payment_amount,\n",
    "        SUM(processing_fee) as total_processing_fees,\n",
    "        AVG(payment_amount) as avg_payment_amount,\n",
    "        SUM(payment_amount + processing_fee) as total_cost\n",
    "    FROM {full_table_name}\n",
    "    \"\"\"\n",
    "    summary_result = con.execute(summary_query).fetchdf()\n",
    "    summary_result.to_csv(\"C:/Users/victoria/Desktop/DE/zz_de/files/payment_summary_statistics.csv\", index=False)\n",
    "\n",
    "    # Payments by Type Analysis\n",
    "    payment_type_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_type,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_amount,\n",
    "        AVG(payment_amount) as avg_amount\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_type\n",
    "    ORDER BY total_amount DESC\n",
    "    \"\"\"\n",
    "    payment_type_result = con.execute(payment_type_query).fetchdf()\n",
    "    payment_type_result.to_csv(\"C:/Users/victoria/Desktop/DE/zz_de/files/payments_by_type.csv\", index=False)\n",
    "\n",
    "    # Payments by Status Analysis  \n",
    "    payment_status_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_status,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_amount,\n",
    "        COUNT(*) * 100.0 / SUM(COUNT(*)) OVER () as percentage\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_status\n",
    "    ORDER BY record_count DESC\n",
    "    \"\"\"\n",
    "    payment_status_result = con.execute(payment_status_query).fetchdf()\n",
    "    payment_status_result.to_csv(\"C:/Users/victoria/Desktop/DE/zz_de/files/payments_by_status.csv\", index=False)\n",
    "\n",
    "    # Payments by Gateway Analysis \n",
    "    gateway_query = f\"\"\"\n",
    "    SELECT \n",
    "        payment_gateway,\n",
    "        COUNT(*) as record_count,\n",
    "        SUM(payment_amount) as total_amount,\n",
    "        COUNT(CASE WHEN payment_status = 'Completed' THEN 1 END) as successful_payments,\n",
    "        COUNT(CASE WHEN payment_status = 'Failed' THEN 1 END) as failed_payments\n",
    "    FROM {full_table_name}\n",
    "    GROUP BY payment_gateway\n",
    "    ORDER BY total_amount DESC\n",
    "    \"\"\"\n",
    "    gateway_result = con.execute(gateway_query).fetchdf()\n",
    "    gateway_result.to_csv(\"C:/Users/victoria/Desktop/DE/zz_de/files/payments_by_gateway.csv\", index=False)\n",
    "    \n",
    "\n",
    "    print(\"Files created:\")\n",
    "    print(\"  - summary_statistics.csv\")\n",
    "    print(\"  - payment_type_result.csv\")\n",
    "    print(\"  - payment_status_result.csv\")\n",
    "    print(\"  - gateway_result.csv\")\n",
    "else:\n",
    "    print(\"No data tables found. Please run the data loading cell first.\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449fd52-bbfa-4ff7-bf67-fa633f60d9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
